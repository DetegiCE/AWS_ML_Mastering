{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k겹 교차 검증\n",
    "- 데이터셋을 훈련 데이터와 테스트 데이터로 나눌 때 발생할 수 있는 가장 큰 단점은 훈련 데이터에서 나타나는 특징이 테스트 데이터에서 나타나지 않을 수 있다는 점\n",
    "\n",
    "1. k 값 선택\n",
    "2. 원본 데이터 섞기\n",
    "3. 원본 데이터를 동일한 크기를 갖는 k개의 데이터셋으로 나누기\n",
    "4. 각 k에 관해서\n",
    "    1. k번째 데이터셋을 테스트 데이터로, 나머지 데이터셋을 훈련 데이터로 사용해 모델 학습\n",
    "    2. k번째 데이터셋에 테스트한 성능 기록\n",
    "5. 개별 모델들의 평균 성능을 계산해 전체 성능 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "fold_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number: 1\n",
      "Training indices: [  0   1   3   5   6   7   8   9  10  13  14  15  16  17  18  19  20  21\n",
      "  22  23  24  26  28  29  30  31  32  33  34  35  36  37  38  39  40  41\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  80  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 136 137 139 142 144 145 146 147 148]\n",
      "Testing indicies: [  2   4  11  12  25  27  62  79  81 135 138 140 141 143 149]\n",
      "Fold number: 2\n",
      "Training indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  31  33  34  35  39  40  41\n",
      "  42  43  44  45  46  49  50  51  52  53  54  55  56  57  58  59  60  62\n",
      "  63  64  65  66  67  68  70  71  72  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 110 111 112 113 115 116 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "Testing indicies: [ 17  30  32  36  37  38  47  48  61  69  73  74 109 114 117]\n",
      "Fold number: 3\n",
      "Training indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  23  24  25  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  89  90  91  92  93\n",
      "  95  96  97  99 100 101 102 103 104 105 106 107 108 109 110 111 113 114\n",
      " 115 116 117 118 119 121 123 124 125 126 127 132 133 134 135 136 137 138\n",
      " 140 141 142 143 144 145 146 147 149]\n",
      "Testing indicies: [ 22  26  52  88  94  98 112 120 122 128 129 130 131 139 148]\n",
      "Fold number: 4\n",
      "Training indices: [  1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  34  36  37  38  39\n",
      "  40  41  42  43  44  45  47  48  49  50  52  53  54  55  56  57  58  59\n",
      "  61  62  63  64  65  66  68  69  71  72  73  74  75  76  77  78  79  80\n",
      "  81  83  84  85  86  87  88  89  90  91  92  94  95  96  97  98  99 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 119 120\n",
      " 121 122 123 125 126 127 128 129 130 131 132 133 134 135 136 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "Testing indicies: [  0  14  33  35  46  51  60  67  70  82  93 100 118 124 137]\n",
      "Fold number: 5\n",
      "Training indices: [  0   1   2   3   4   5   7   8   9  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  30  32  33  34  35  36  37  38  39\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  60  61  62  63  64  65  66  67  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  87  88  89  90  91  92  93  94  95  97  98\n",
      " 100 101 102 103 104 105 106 109 110 111 112 113 114 115 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 137 138 139\n",
      " 140 141 142 143 144 145 147 148 149]\n",
      "Testing indicies: [  6  10  29  31  40  59  68  86  96  99 107 108 116 136 146]\n",
      "Fold number: 6\n",
      "Training indices: [  0   1   2   3   4   5   6   7   9  10  11  12  13  14  15  17  18  19\n",
      "  20  21  22  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  43  44  45  46  47  48  49  50  51  52  56  57  58  59  60\n",
      "  61  62  63  64  65  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
      "  80  81  82  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 105 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 143 144 145 146 148 149]\n",
      "Testing indicies: [  8  16  23  42  53  54  55  66  83  84 103 104 106 142 147]\n",
      "Fold number: 7\n",
      "Training indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  40  41  42  43  45  46  47  48  49  50  51  52  53  54  55\n",
      "  57  58  59  60  61  62  63  64  66  67  68  69  70  73  74  76  79  80\n",
      "  81  82  83  84  85  86  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 102 103 104 105 106 107 108 109 110 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 127 128 129 130 131 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "Testing indicies: [ 39  44  56  65  71  72  75  77  78  87 101 111 125 126 132]\n",
      "Fold number: 8\n",
      "Training indices: [  0   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  31  32  33  35  36  37  38  39\n",
      "  40  41  42  43  44  45  46  47  48  51  52  53  54  55  56  57  59  60\n",
      "  61  62  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
      "  80  81  82  83  84  85  86  87  88  89  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 106 107 108 109 110 111 112 113 114 116 117 118 119\n",
      " 120 122 123 124 125 126 127 128 129 130 131 132 133 135 136 137 138 139\n",
      " 140 141 142 143 144 146 147 148 149]\n",
      "Testing indicies: [  1   9  24  34  49  50  58  63  90  91 105 115 121 134 145]\n",
      "Fold number: 9\n",
      "Training indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  14  16  17  19  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  44  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  65  66  67  68  69  70  71  72  73  74  75  77  78  79  81\n",
      "  82  83  84  86  87  88  90  91  92  93  94  95  96  98  99 100 101 103\n",
      " 104 105 106 107 108 109 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "Testing indicies: [ 13  15  18  20  21  43  45  64  76  80  85  89  97 102 110]\n",
      "Fold number: 10\n",
      "Training indices: [  0   1   2   4   6   8   9  10  11  12  13  14  15  16  17  18  20  21\n",
      "  22  23  24  25  26  27  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  93  94  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 114 115 116 117\n",
      " 118 120 121 122 124 125 126 128 129 130 131 132 134 135 136 137 138 139\n",
      " 140 141 142 143 145 146 147 148 149]\n",
      "Testing indicies: [  3   5   7  19  28  41  57  92  95 113 119 123 127 133 144]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "df_iris_features = pd.DataFrame(data=iris_dataset.data, columns=iris_dataset.feature_names)\n",
    "df_iris_target = pd.DataFrame(data=iris_dataset.target, columns=['class'])\n",
    "\n",
    "for train_indices, test_indices in kf.split(df_iris_features):\n",
    "    print('Fold number:', fold_number)\n",
    "    print('Training indices:', train_indices)\n",
    "    print('Testing indicies:', test_indices)\n",
    "    \n",
    "    fold_number = fold_number + 1\n",
    "    \n",
    "    df_iris_features_train = df_iris_features.iloc[train_indices]\n",
    "    df_iris_target_train = df_iris_target.iloc[train_indices]\n",
    "    df_iris_features_test = df_iris_features.iloc[test_indices]\n",
    "    df_iris_target_test = df_iris_target.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
