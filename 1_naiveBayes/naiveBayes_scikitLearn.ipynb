{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "import os\n",
    "\n",
    "src_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [word.strip() for word in open(src_path+'/stop_words.txt').readlines()]\n",
    "\n",
    "with open(src_path+'/dem.txt', 'r') as file:\n",
    "    dem_text = [line.strip('\\n') for line in file]\n",
    "    \n",
    "with open(src_path+'/gop.txt', 'r') as file:\n",
    "    gop_text = [line.strip('\\n') for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장의 매트릭스화를 진행 (첫 800단어만)\n",
    "vectorizer = CountVectorizer(input=dem_text+gop_text,\n",
    "                            stop_words=stop_words,\n",
    "                            max_features=800)\n",
    "dem_bow = vectorizer.fit_transform(dem_text)\n",
    "gop_bow = vectorizer.fit_transform(gop_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 800), (200, 800))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dem_bow.shape, gop_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델의 훈련을 위한 배열 제공\n",
    "x = sparse.vstack((dem_bow, gop_bow))\n",
    "\n",
    "#레이블 벡터를 만들기 위해 dem은 1, gop는 0인 벡터를 조립\n",
    "ones = np.ones(200)\n",
    "zeros = np.zeros(200)\n",
    "y = np.hstack((ones, zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 800), (400,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델의 훈련 전, 트윗들을 무작위로 분할하여 75%는 모델을 만드는데 사용하고, 나머지는 예측이 잘 되는지를 확인하는데 사용\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 800), (100, 800), (300,), (100,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 및 테스트셋의 준비가 되었기 때문에 naive bayes(0과 1이므로 bernoulli naive bayes)로 모델 훈련 진행\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "naive_bayes = BernoulliNB()\n",
    "model = naive_bayes.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측 값을 얻음\n",
    "y_predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측 값과 얼마나 일치하는지 확인 (정확도))\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파이프라인을 이용한 모델링\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dem_text+gop_text,\n",
    "                                                   test_size=0.25,\n",
    "                                                   random_state=5)\n",
    "pipeline = Pipeline([('vect', vectorizer), ('nb', naive_bayes)])\n",
    "pipeline_model = pipeline.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
